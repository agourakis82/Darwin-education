#!/usr/bin/env tsx
/**
 * Curadoria Automatizada de Quest√µes com IA
 *
 * Usa GLM-5 (Z.ai) ou Grok (xAI) para gerar explica√ß√µes de alta qualidade
 * para quest√µes sem explica√ß√£o completa.
 *
 * Usage:
 *   pnpm tsx scripts/curate_questions_ai.ts --area cirurgia --limit 10 --dry-run
 *   pnpm tsx scripts/curate_questions_ai.ts --area saude_coletiva --limit 50
 *   pnpm tsx scripts/curate_questions_ai.ts --batch-id <uuid> --apply
 *
 * Flags:
 *   --area <area>        √Årea ENAMED (cirurgia, saude_coletiva, etc.)
 *   --limit <n>          N√∫mero de quest√µes a processar (default: 10)
 *   --dry-run            Gera explica√ß√µes mas n√£o salva no banco
 *   --apply              Aplica explica√ß√µes geradas (ap√≥s review)
 *   --model <name>       Modelo IA: glm-5, grok (default: glm-5)
 *   --batch-id <id>      ID do batch para aplicar
 */

import { createClient } from '@supabase/supabase-js'
import fs from 'node:fs'
import path from 'node:path'
import { randomUUID } from 'node:crypto'
import { readFileSync } from 'node:fs'
import { join } from 'node:path'

// Load environment variables from apps/web/.env.local
function loadEnvFile() {
  const ROOT = join(__dirname, '..')
  try {
    const envFile = readFileSync(join(ROOT, 'apps/web/.env.local'), 'utf-8')
    for (const line of envFile.split('\n')) {
      const trimmed = line.trim()
      if (trimmed && !trimmed.startsWith('#')) {
        const eqIdx = trimmed.indexOf('=')
        if (eqIdx > 0) {
          const key = trimmed.slice(0, eqIdx)
          const value = trimmed.slice(eqIdx + 1)
          if (!process.env[key]) {  // Don't override existing env vars
            process.env[key] = value
          }
        }
      }
    }
  } catch {
    // .env.local not found - rely on shell environment
    console.warn('‚ö†Ô∏è  apps/web/.env.local not found, using shell environment variables')
  }
}

// Call it immediately
loadEnvFile()

// Configura√ß√£o
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL!
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY!
const GROK_API_KEY = process.env.XAI_API_KEY!

// Suporte para MiniMax (Anthropic-compatible), GLM-5 ou Grok
const MINIMAX_API_KEY = process.env.MINIMAX_API_KEY!
const AI_CONFIG = {
  'minimax': {
    apiUrl: 'https://api.minimax.io/anthropic/v1/messages',
    apiKey: MINIMAX_API_KEY,
    model: 'MiniMax-M2.5-highspeed', // 100 tps, super r√°pido!
    isAnthropicFormat: true, // Usa formato Anthropic SDK
  },
  'glm-5': {
    apiUrl: 'https://open.bigmodel.cn/api/paas/v4/chat/completions',
    apiKey: process.env.GLM_API_KEY || GROK_API_KEY,
    model: 'glm-4-plus',
    isAnthropicFormat: false,
  },
  'grok': {
    apiUrl: 'https://api.x.ai/v1/chat/completions',
    apiKey: GROK_API_KEY,
    model: 'grok-4-1-fast-reasoning',
    isAnthropicFormat: false,
  },
}

const supabase = createClient(SUPABASE_URL, SUPABASE_KEY)

// Colors
const c = {
  reset: '\x1b[0m',
  bright: '\x1b[1m',
  red: '\x1b[31m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  cyan: '\x1b[36m',
}

function log(msg: string, color = c.reset) {
  console.log(`${color}${msg}${c.reset}`)
}

// Parse args
function parseArgs() {
  const args = process.argv.slice(2)
  const parsed: any = {
    area: null,
    limit: 10,
    dryRun: false,
    apply: false,
    model: 'minimax', // Default: MiniMax M2.5-highspeed (100 tps!)
    batchId: null,
  }

  for (let i = 0; i < args.length; i++) {
    const arg = args[i]
    if (arg === '--area') parsed.area = args[++i]
    else if (arg === '--limit') parsed.limit = parseInt(args[++i])
    else if (arg === '--dry-run') parsed.dryRun = true
    else if (arg === '--apply') parsed.apply = true
    else if (arg === '--model') parsed.model = args[++i]
    else if (arg === '--batch-id') parsed.batchId = args[++i]
  }

  return parsed
}

// Prompt template para gerar explica√ß√µes
function buildPrompt(question: any): string {
  const optionsText = question.options
    .map((opt: any, i: number) => `${opt.letter}) ${opt.text}`)
    .join('\n')

  const correctLetter = question.options[question.correct_index]?.letter || 'A'

  return `Voc√™ √© um especialista em educa√ß√£o m√©dica e prepara√ß√£o para o ENAMED (Exame Nacional de Avalia√ß√£o da Forma√ß√£o M√©dica) brasileiro.

Sua tarefa √© escrever uma EXPLICA√á√ÉO COMPLETA e DID√ÅTICA para a quest√£o abaixo, ajudando estudantes de medicina a entenderem o racioc√≠nio cl√≠nico correto.

# QUEST√ÉO:

${question.stem}

**Alternativas:**
${optionsText}

**Gabarito Correto:** ${correctLetter}

---

# INSTRU√á√ïES PARA A EXPLICA√á√ÉO:

1. **Identificar dados-chave do caso cl√≠nico:**
   - Idade, g√™nero, queixa principal
   - Achados de exame f√≠sico relevantes
   - Exames complementares (se houver)

2. **Explicar o racioc√≠nio para a resposta CORRETA:**
   - Por que a alternativa ${correctLetter} √© a MELHOR resposta?
   - Que guideline, consenso ou evid√™ncia suporta isso?
   - Qual o racioc√≠nio fisiopatol√≥gico ou cl√≠nico?

3. **Explicar por que CADA alternativa INCORRETA est√° errada:**
   - Alternativa A (se incorreta): [raz√£o espec√≠fica]
   - Alternativa B (se incorreta): [raz√£o espec√≠fica]
   - Alternativa C (se incorreta): [raz√£o espec√≠fica]
   - Alternativa D (se incorreta): [raz√£o espec√≠fica]

4. **Adicionar dicas pr√°ticas:**
   - Palavras-chave do enunciado que ajudam a chegar na resposta
   - Armadilhas comuns (erros que estudantes cometem)

5. **Refer√™ncias (se aplic√°vel):**
   - Guideline, consenso ou protocolo relevante (ex: ESC 2021, ACOG 2020, MS 2019)

---

# FORMATO DA EXPLICA√á√ÉO (MARKDOWN):

**Resposta Correta: ${correctLetter}**

[Explica√ß√£o do racioc√≠nio cl√≠nico: 150-200 palavras sobre POR QUE a alternativa correta est√° certa, baseado em dados do caso e guideline/evid√™ncia]

**Por que as outras alternativas est√£o incorretas:**

- **[Letra A/B/C/D]**: [30-50 palavras explicando por que est√° errada - erro conceitual, n√£o se aplica ao caso, conduta sub√≥tima, etc.]
- **[Letra A/B/C/D]**: [30-50 palavras]
- **[Letra A/B/C/D]**: [30-50 palavras]

**Dica Cl√≠nica:** [20-30 palavras com palavra-chave ou armadilha comum]

**Refer√™ncia:** [Guideline ou consenso, se aplic√°vel]

---

IMPORTANTE:
- Use linguagem clara e did√°tica (como se estivesse explicando para um colega)
- Seja objetivo e conciso (250-350 palavras TOTAL)
- Foque no racioc√≠nio cl√≠nico, n√£o apenas em decorar a resposta
- Use markdown para estruturar (**, -, etc.)
- N√ÉO repita o enunciado da quest√£o na explica√ß√£o
- N√ÉO use emojis

Gere APENAS a explica√ß√£o no formato solicitado, sem introdu√ß√£o ou conclus√£o extra.`
}

// Chamar API de IA (MiniMax, GLM-5 ou Grok)
async function generateExplanation(question: any, modelName: string): Promise<string | null> {
  const config = AI_CONFIG[modelName as keyof typeof AI_CONFIG]
  if (!config) {
    log(`‚ùå Modelo desconhecido: ${modelName}`, c.red)
    return null
  }

  const prompt = buildPrompt(question)

  try {
    // MiniMax usa formato Anthropic Messages API
    if (config.isAnthropicFormat) {
      const response = await fetch(config.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.apiKey}`,
          'anthropic-version': '2023-06-01',
        },
        body: JSON.stringify({
          model: config.model,
          max_tokens: 1000,
          temperature: 0.3,
          system: 'Voc√™ √© um especialista em educa√ß√£o m√©dica e prepara√ß√£o para o ENAMED.',
          messages: [
            {
              role: 'user',
              content: [{ type: 'text', text: prompt }],
            },
          ],
        }),
      })

      if (!response.ok) {
        const error = await response.text()
        log(`‚ùå Erro na API (${response.status}): ${error}`, c.red)
        return null
      }

      const data = await response.json()

      // Extrair texto de content blocks (pode ter thinking + text)
      let explanation = ''
      for (const block of data.content || []) {
        if (block.type === 'text') {
          explanation += block.text
        }
      }

      if (!explanation) {
        log('‚ùå Resposta vazia da API', c.red)
        return null
      }

      return explanation.trim()
    }
    // OpenAI-compatible format (GLM-5, Grok)
    else {
      const response = await fetch(config.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.apiKey}`,
        },
        body: JSON.stringify({
          model: config.model,
          messages: [
            {
              role: 'system',
              content: 'Voc√™ √© um especialista em educa√ß√£o m√©dica e prepara√ß√£o para o ENAMED.',
            },
            {
              role: 'user',
              content: prompt,
            },
          ],
          temperature: 0.3,
          max_tokens: 800,
        }),
      })

      if (!response.ok) {
        const error = await response.text()
        log(`‚ùå Erro na API (${response.status}): ${error}`, c.red)
        return null
      }

      const data = await response.json()
      const explanation = data.choices?.[0]?.message?.content

      if (!explanation) {
        log('‚ùå Resposta vazia da API', c.red)
        return null
      }

      return explanation.trim()
    }
  } catch (error: any) {
    log(`‚ùå Erro ao chamar API: ${error.message}`, c.red)
    return null
  }
}

// Buscar quest√µes sem explica√ß√£o
async function fetchQuestionsToProcess(area: string | null, limit: number) {
  // Fetch all questions for the area, then filter locally for missing/placeholder explanations
  // This catches: null, empty, "em elabora√ß√£o", "pendente de revis√£o", or very short (<100 chars)
  const fetchLimit = 1000
  let query = supabase
    .from('questions')
    .select('*')
    .limit(fetchLimit)

  if (area) {
    query = query.eq('area', area)
  }

  const { data, error } = await query

  if (error) {
    log(`‚ùå Erro ao buscar quest√µes: ${error.message}`, c.red)
    return []
  }

  // Filter locally for questions needing curation
  const needsCuration = (data || []).filter((q: any) =>
    !q.explanation ||
    q.explanation.length < 100 ||
    q.explanation.includes('em elabora√ß√£o') ||
    q.explanation.includes('pendente de revis√£o')
  )

  return needsCuration.slice(0, limit)
}

// Processar batch
async function processBatch(questions: any[], modelName: string, dryRun: boolean) {
  const batchId = randomUUID()
  const batchDir = path.join(process.cwd(), '.curate_batches', batchId)
  fs.mkdirSync(batchDir, { recursive: true })

  log(`\nü§ñ Processando batch: ${batchId}`, c.cyan)
  log(`üì¶ Modelo: ${modelName}`, c.cyan)
  log(`üìÑ Quest√µes: ${questions.length}`, c.cyan)
  log(`üíæ Salvando em: ${batchDir}\n`, c.cyan)

  const results = []

  for (let i = 0; i < questions.length; i++) {
    const q = questions[i]
    const progress = `[${i + 1}/${questions.length}]`

    log(`${progress} Processando quest√£o ${q.id.substring(0, 8)}...`, c.blue)
    log(`   √Årea: ${q.area}`, c.blue)
    log(`   Stem: ${q.stem.substring(0, 80)}...`, c.blue)

    const explanation = await generateExplanation(q, modelName)

    if (!explanation) {
      log(`${progress} ‚ùå Falha ao gerar explica√ß√£o`, c.red)
      results.push({ questionId: q.id, status: 'failed', explanation: null })
      continue
    }

    log(`${progress} ‚úÖ Explica√ß√£o gerada (${explanation.length} chars)`, c.green)

    // Salvar JSON individual
    const questionFile = path.join(batchDir, `${q.id}.json`)
    fs.writeFileSync(
      questionFile,
      JSON.stringify(
        {
          questionId: q.id,
          area: q.area,
          stem: q.stem,
          options: q.options,
          correct_index: q.correct_index,
          old_explanation: q.explanation,
          new_explanation: explanation,
          generated_at: new Date().toISOString(),
          model: modelName,
        },
        null,
        2
      )
    )

    results.push({
      questionId: q.id,
      area: q.area,
      status: 'success',
      explanation,
    })

    // Rate limiting (evitar throttle)
    await new Promise((resolve) => setTimeout(resolve, 1000)) // 1s entre requests
  }

  // Salvar resumo do batch
  const summary = {
    batchId,
    modelName,
    processedAt: new Date().toISOString(),
    totalQuestions: questions.length,
    successful: results.filter((r) => r.status === 'success').length,
    failed: results.filter((r) => r.status === 'failed').length,
    dryRun,
    results,
  }

  const summaryFile = path.join(batchDir, 'summary.json')
  fs.writeFileSync(summaryFile, JSON.stringify(summary, null, 2))

  log(`\n‚úÖ Batch completo!`, c.green)
  log(`üìä Sucesso: ${summary.successful}/${summary.totalQuestions}`, c.green)
  log(`üìÅ Arquivos salvos em: ${batchDir}`, c.cyan)

  if (dryRun) {
    log(`\n‚ö†Ô∏è  DRY RUN - Explica√ß√µes N√ÉO foram aplicadas ao banco`, c.yellow)
    log(`   Para aplicar: pnpm tsx scripts/curate_questions_ai.ts --batch-id ${batchId} --apply`, c.yellow)
  }

  return { batchId, summary }
}

// Aplicar batch ao banco
async function applyBatch(batchId: string) {
  const batchDir = path.join(process.cwd(), '.curate_batches', batchId)

  if (!fs.existsSync(batchDir)) {
    log(`‚ùå Batch n√£o encontrado: ${batchId}`, c.red)
    return
  }

  const summaryFile = path.join(batchDir, 'summary.json')
  const summary = JSON.parse(fs.readFileSync(summaryFile, 'utf8'))

  log(`\nüöÄ Aplicando batch ${batchId} ao banco...`, c.cyan)
  log(`üì¶ ${summary.successful} quest√µes para atualizar\n`, c.cyan)

  let updated = 0
  let failed = 0

  for (const result of summary.results) {
    if (result.status !== 'success') continue

    const questionFile = path.join(batchDir, `${result.questionId}.json`)
    const questionData = JSON.parse(fs.readFileSync(questionFile, 'utf8'))

    const { error } = await supabase
      .from('questions')
      .update({ explanation: questionData.new_explanation })
      .eq('id', result.questionId)

    if (error) {
      log(`‚ùå Erro ao atualizar ${result.questionId}: ${error.message}`, c.red)
      failed++
    } else {
      log(`‚úÖ Atualizado: ${result.questionId} (${result.area})`, c.green)
      updated++
    }
  }

  log(`\n‚úÖ Aplica√ß√£o completa!`, c.green)
  log(`üìä Atualizadas: ${updated}`, c.green)
  log(`‚ùå Falharam: ${failed}`, failed > 0 ? c.red : c.green)

  // Marcar batch como aplicado
  summary.appliedAt = new Date().toISOString()
  fs.writeFileSync(summaryFile, JSON.stringify(summary, null, 2))
}

// Main
async function main() {
  const args = parseArgs()

  log('\nü§ñ CURADORIA AUTOMATIZADA DE QUEST√ïES COM IA', c.bright + c.cyan)
  log('='.repeat(60), c.cyan)

  // Modo: aplicar batch existente
  if (args.apply && args.batchId) {
    await applyBatch(args.batchId)
    return
  }

  // Validar √°rea
  if (!args.area && !args.apply) {
    log('\n‚ùå Erro: --area √© obrigat√≥rio', c.red)
    log('√Åreas v√°lidas: cirurgia, saude_coletiva, pediatria, ginecologia_obstetricia, clinica_medica\n', c.yellow)
    process.exit(1)
  }

  // Buscar quest√µes
  log(`\nüîç Buscando quest√µes sem explica√ß√£o...`, c.blue)
  log(`   √Årea: ${args.area || 'todas'}`, c.blue)
  log(`   Limite: ${args.limit}\n`, c.blue)

  const questions = await fetchQuestionsToProcess(args.area, args.limit)

  if (questions.length === 0) {
    log('‚úÖ Nenhuma quest√£o encontrada sem explica√ß√£o!', c.green)
    return
  }

  log(`üì¶ ${questions.length} quest√µes encontradas\n`, c.cyan)

  // Processar
  const { batchId } = await processBatch(questions, args.model, args.dryRun)

  // Se n√£o for dry-run, perguntar se quer aplicar
  if (!args.dryRun) {
    log(`\n‚ö†Ô∏è  Batch gerado mas n√£o aplicado. Revise os arquivos em:`, c.yellow)
    log(`   .curate_batches/${batchId}/`, c.yellow)
    log(`\n   Para aplicar: pnpm tsx scripts/curate_questions_ai.ts --batch-id ${batchId} --apply\n`, c.yellow)
  }
}

main().catch((error) => {
  log(`\n‚ùå Erro fatal: ${error.message}`, c.red)
  console.error(error)
  process.exit(1)
})
